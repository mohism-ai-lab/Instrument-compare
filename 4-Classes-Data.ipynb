{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#General\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# System\n",
    "import os, fnmatch\n",
    "\n",
    "# Random Seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Audio\n",
    "import librosa.display, librosa\n",
    "\n",
    "# Configurations\n",
    "path='./data/instruments/'\n",
    "nClasses = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 644 audio files in ./data/instruments/\n"
     ]
    }
   ],
   "source": [
    "# Get files in data path for wav\n",
    "\n",
    "files = []\n",
    "for root, dirnames, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, '*.wav'):\n",
    "        files.append(os.path.join(root, filename))\n",
    "\n",
    "print(\"found %d audio files in %s\"%(len(files),path))\n",
    "#print(\"files=\" + str(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.len=644\n",
      "color_list.len=644\n"
     ]
    }
   ],
   "source": [
    "# Get Labels\n",
    "labels =[]\n",
    "classes=['bassoon','clarinet','saxphone', 'violin']\n",
    "color_dict={'bassoon':'blue', 'clarinet':'red', 'saxphone':'green', 'violin':'black'}\n",
    "color_list=[]\n",
    "for filename in files:\n",
    "    for name in classes:\n",
    "        if fnmatch.fnmatchcase(filename, '*'+name+'*'):\n",
    "            labels.append(name)\n",
    "            color_list.append(color_dict[name])\n",
    "            break\n",
    "    else:\n",
    "        labels.append('other')\n",
    "\n",
    "print(\"labels.len=\" + str(len(labels)))\n",
    "print(\"color_list.len=\" + str(len(color_list)))\n",
    "#print(\"labels=\" + str(labels))\n",
    "#print(\"color_list=\" + str(color_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes: bassoon, clarinet, saxphone, violin\n",
      "classes_num.shape=(644,)\n"
     ]
    }
   ],
   "source": [
    "# Encode Labels\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(labels)\n",
    "print(len(labelencoder.classes_), \"classes:\", \", \".join(list(labelencoder.classes_)))\n",
    "classes_num = labelencoder.transform(labels)\n",
    "print(\"classes_num.shape=\" + str(classes_num.shape))\n",
    "#print(\"classes_num=\" + str(classes_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Signal Processing Parameters\n",
    "fs = 44100         # Sampling Frequency\n",
    "n_fft = 2048       # length of the FFT window\n",
    "hop_length = 512   # Number of samples between successive frames\n",
    "n_mels = 128     # Number of Mel bands\n",
    "n_mfcc = 15        # Number of MFCCs\n",
    "\n",
    "# Machine Learning Parameters\n",
    "testset_size = 0.25 #Percentage of data for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to Calculate MFCC, Delta_MFCC and Delta2_MFCC\n",
    "def get_features(y, sr=fs):\n",
    "    S = librosa.feature.melspectrogram(y, sr=fs, n_mels=n_mels)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=n_mfcc)\n",
    "    feature_vector = np.mean(mfcc,1)\n",
    "    #feature_vector = (feature_vector-np.mean(feature_vector))/np.std(feature_vector)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 644 feature vectors\n"
     ]
    }
   ],
   "source": [
    "# Load audio files, calculate features and create feature vectors\n",
    "feature_vectors = []\n",
    "sound_paths = []\n",
    "for i,f in enumerate(files):\n",
    "    #print (\"get %d of %d = %s\"%(i+1, len(files), f))\n",
    "    try:\n",
    "        y, sr = librosa.load(f, sr=fs)\n",
    "        y/=y.max() #Normalize\n",
    "        if len(y) < 2:\n",
    "            print(\"Error loading %s\" % f)\n",
    "            continue\n",
    "        feat = get_features(y, sr)\n",
    "        #print(\"feat.shape=\" + str(feat.shape))\n",
    "        #feat.shape=(13,)\n",
    "        feature_vectors.append(feat)\n",
    "        sound_paths.append(f)\n",
    "    except Exception as e:\n",
    "        print(\"Error loading %s. Error: %s\" % (f,e))\n",
    "        \n",
    "print(\"Calculated %d feature vectors\"%len(feature_vectors))\n",
    "#print(\"feature_vectors.type=\" + str(type(feature_vectors)))\n",
    "#print(\"feature_vectors[0].type=\" + str(type(feature_vectors[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors shape: (644, 15)\n"
     ]
    }
   ],
   "source": [
    "# Scale features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_feature_vectors = scaler.fit_transform(np.array(feature_vectors))\n",
    "print(\"Feature vectors shape:\",scaled_feature_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test Set\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=testset_size, random_state=0)\n",
    "splits = splitter.split(scaled_feature_vectors, classes_num)\n",
    "for train_index, test_index in splits:\n",
    "    train_set = scaled_feature_vectors[train_index]\n",
    "    test_set = scaled_feature_vectors[test_index]\n",
    "    train_classes = classes_num[train_index]\n",
    "    test_classes = classes_num[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape: (483, 15)\n",
      "test_set shape: (161, 15)\n",
      "train_classes shape: (483,)\n",
      "test_classes shape: (161,)\n"
     ]
    }
   ],
   "source": [
    "# Check Set Shapes\n",
    "print(\"train_set shape:\",train_set.shape)\n",
    "print(\"test_set shape:\",test_set.shape)\n",
    "print(\"train_classes shape:\",train_classes.shape)\n",
    "print(\"test_classes shape:\",test_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf', C = 10.0, gamma=0.1) \n",
    "svclassifier.fit(train_set, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the Test Set\n",
    "#predicted_labels = model_svm.predict(test_set)\n",
    "predicted_labels = svclassifier.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy=1.0\n"
     ]
    }
   ],
   "source": [
    "#print(\"predicted_labels=\" + str(predicted_labels))\n",
    "test_accuracy = svclassifier.score(test_set, test_classes)\n",
    "print(\"test_accuracy=\" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
